{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"HW = 'humpback-whale-identification'\n# TRAIN = '../input/humpback-whale-identification/train/'\nTRAIN_CROPPED = \"whales-cropped/cropped_train/cropped_train/\"\nTRAIN_CROPPED_IN = '../input/' + TRAIN_CROPPED\n\n# TEST = '../input/humpback-whale-identification/test/'\nTEST_CROPPED = \"whales-cropped/cropped_test/cropped_test/\"\nTEST_CROPPED_IN = '../input/' + TEST_CROPPED\n\nLABELS = '../input/humpback-whale-identification/train.csv'\nSAMPLE_SUB = '../input/humpback-whale-identification/sample_submission.csv'\n\ntrain = pd.read_csv(LABELS)\nprint(\"With new_whale:\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1dea1195c936c9dd22093483b7a4b32746a978b"},"cell_type":"code","source":"MODEL_F = 'Model_ResNet50_30epocs.h5'\nWEIGHTS_F = 'Weights_ResNet50_30epocs.h5'\nMODEL = '../input/resnet50-pretrained/'+ MODEL_F\nWEIGHTS = '../input/resnet50-pretrained/'+ WEIGHTS_F","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d8226025070bee28da643e57f925a6c3c075f63b"},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5c2094ad7d97a11ecd4f7c7dd35cc2cf3fa8ae59"},"cell_type":"code","source":"import random \nfrom IPython.display import Image\nprint(\"Example whale image\")\n\n#show sample image\nname = random.choice(train['Image'])\nprint(name)\nImage(filename = TRAIN_CROPPED_IN + name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9cd0a1227409ddd9f0154cd51136b84615866d5"},"cell_type":"code","source":"train_images = train.set_index('Image')\nnew_whale_train = train_images[train_images.Id == \"new_whale\"]  # only new_whale dataset\n# whales_train = train_images[~(train_images.Id == \"new_whale\")]  # no new_whale dataset, used for training\ncriteria = train['Id'] != 'new_whale'\nwhales_train = train[criteria]\n    \nprint(\"Without new_whale:\")\nwhales_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10d3b64626005f5f0b1714bed949c7178674b6f2"},"cell_type":"code","source":"unique_labels = np.unique(whales_train.Id.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe40c404327ac23b61cf2e1493dd033ece5b7d71"},"cell_type":"code","source":"whales_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f900184097fc35e7feedde2cc05e5cd00c84d9a"},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nfrom keras import layers\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom keras.models import Model\n\nimport keras.backend as K\nfrom keras.models import Sequential\nfrom PIL import Image\nimport gc\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c60eeebdd134f57556c6e7ef7f7e8151801cae78"},"cell_type":"code","source":"IMAGE_HEIGHT = 100\nIMAGE_WIDTH = 100\n\ndef prepareImages(data, m, dataset):\n    print(\"Preparing images\")\n    X_train = np.zeros((m, IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n    count = 0\n    \n    for fig in data['Image']:          \n        filepath = \"../input/\"+dataset+\"/\"+fig\n        img = image.load_img(filepath)\n        img = img.convert(mode=\"RGB\")\n        \n        #load images into images of required size\n        img = img.resize((IMAGE_HEIGHT, IMAGE_WIDTH))\n        x = image.img_to_array(img)\n        x = preprocess_input(x)\n\n        X_train[count] = x\n        if (count%500 == 0):\n#             plt.imshow(img)\n            print(\"Processing image: \", count+1, \", \", fig)\n            \n        count += 1\n    \n    return X_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8297ce8385ac189ada58f6e59afff905db5997a8"},"cell_type":"code","source":"def remove_new_whale():    \n    labels_dict = dict()\n    labels_list = []\n\n    for i in range(len(unique_labels)):\n        labels_dict[unique_labels[i]] = i\n        labels_list.append(unique_labels[i])\n\n    print(\"Number of classes: {}\".format(len(unique_labels)))\n\n    print(np.shape(labels_list))\n    labels_list = np.array(labels_list)\n    return labels_list, labels_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1aefc26361c9081d77c1bc56b8be852429e8be76"},"cell_type":"code","source":"labels_list, labels_dict = remove_new_whale()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2adba4fe7c23e6811da09d977bd055b991099a7c"},"cell_type":"code","source":"whales_train.Id = whales_train.Id.apply(lambda x: labels_dict[x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f1e9bb973baf816008dce1381ba518830ffc003c"},"cell_type":"code","source":"print(whales_train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"97b1b1f7fdc53416b5216ce20c55b0b5d084d202"},"cell_type":"code","source":"def prepare_labels(y):\n    values = np.array(y)\n    label_encoder = LabelEncoder()\n    integer_encoded = label_encoder.fit_transform(values)\n    # print(integer_encoded)\n\n    onehot_encoder = OneHotEncoder(sparse=False)\n    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n#     print(integer_encoded)\n    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n#     print(onehot_encoded)\n\n    y = onehot_encoded\n    print(y.shape)\n    return y, label_encoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ec77f361f115c9f1e0047000c52d867460167a5"},"cell_type":"code","source":"y, label_encoder = prepare_labels(whales_train['Id'])\ny.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7043e0c7ebadd67108055625c71147d8a4d04226"},"cell_type":"code","source":"%matplotlib inline\nX = prepareImages(whales_train, whales_train.shape[0], TRAIN_CROPPED)\nX /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10dbfd1a18557125abc46b6aec885a66a4dcd62e"},"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D, Dropout\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.losses import binary_crossentropy\n\nCLASSES = 5004\n    \n# setup model\n# base_model = ResNet50(weights='imagenet', include_top=False, input_shape = (100, 100, 3))\n\n# x = base_model.output\n# x = GlobalAveragePooling2D(name='avg_pool')(x)\n# x = Dropout(0.4)(x)\n# predictions = Dense(CLASSES, activation='softmax')(x)\n# model = Model(inputs=base_model.input, outputs=predictions)\n   \n# # transfer learning\n# for layer in base_model.layers:\n#   layer.trainable = True\n      \n# model.compile(optimizer='adam',\n#               loss='categorical_crossentropy',\n#               metrics=['accuracy'])\n\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6164ebdca0950095114b245ca9e834c43d2947af"},"cell_type":"code","source":"# print(\"Train set shape: \"+ str(np.shape(X)))\n# print(np.shape(whales_train['Id']))\n# history = model.fit(X, y, epochs=30, batch_size=100, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ad42778204ccee6119faa6eaebd69edc66cfc6a"},"cell_type":"code","source":"# model.save(MODEL_F)\n# print(\"Saved model architecture to disk\")\n# model.save_weights(WEIGHTS_F)\n# print(\"Saved model weights to disk\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4a1a6be045ecb003b33b899ed11ebedbde4befd"},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a828703f48eb3defa1ed5d5b7ec058b5c2e3f1ac"},"cell_type":"code","source":"from keras.models import load_model\n\n# returns a compiled model\n# identical to the previous cell\nmodel = load_model(MODEL)\nprint(\"Loaded model architecture from disk\")\n\nmodel.load_weights(WEIGHTS)\nprint(\"Loaded model weights from disk\")\nmodel.summary()\n\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3540f0749dde1b7758f6ea8c4fccc5c662b03635"},"cell_type":"markdown","source":"# Train more with augmented data <a name=\"flow\"></a>\n____"},{"metadata":{"trusted":true,"_uuid":"212b90e62fbfc1c350b16c719f8426e1f713022a"},"cell_type":"code","source":"ROTATE = 20\nEPOCHS = 15\nBATCH = 100\n\ntrain_datagen = ImageDataGenerator(\n    fill_mode='nearest',\n    validation_split = 0.1,\n    rotation_range=ROTATE,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=False)\n\n# compute quantities required for featurewise normalization\n# (std, mean, and principal components if ZCA whitening is applied)\ntrain_datagen.fit(X)\n\n# fits the model on batches with real-time data augmentation:\nhistory = model.fit_generator(train_datagen.flow(X, y, batch_size=BATCH),\n                    steps_per_epoch=len(X) / BATCH, epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bad5396ba6233fbd18690cfe19842b8c518fd249"},"cell_type":"code","source":"model.save(MODEL_F)\nprint(\"Saved model architecture to disk\")\nmodel.save_weights(WEIGHTS_F)\nprint(\"Saved model weights to disk\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adbc27074f20f494670395569611c751963d2140"},"cell_type":"markdown","source":"# Plot train results <a name=\"flow\"></a>\n____"},{"metadata":{"trusted":true,"_uuid":"4803d5306931ad157b9fb9bf3923166d8fd68a0c"},"cell_type":"code","source":"def plot_accuracy(history, should_plot_val = False):\n    acc = history.history['acc']\n    l1 = plt.plot(acc, label='acc')\n    \n    if should_plot_val:\n        val_acc = history.history['val_acc']\n        l2 = plt.plot(val_acc, label='val_acc')\n        \n    plt.legend(loc=2, fontsize=\"small\")\n    plt.title('Model accuracy')\n    plt.ylabel('Accuracy')\n    plt.xlabel('Epoch')\n    plt.show()\n    \ndef plot_loss(history, should_plot_val = False):\n    loss = history.history['loss']\n    l1 = plt.plot(loss, label='loss')\n    \n    if should_plot_val:\n        val_loss = history.history['val_loss']\n        plt.plot(val_loss, label='val_loss')\n        \n    plt.legend(loc=2, fontsize=\"small\")\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2642d18e30e2731f7d4750ba6fd01ec11188dd92"},"cell_type":"code","source":"plot_accuracy(history)\nplot_loss(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"848dd2761765e9512ff700372e34b39c469ede1e"},"cell_type":"code","source":"test = os.listdir(TEST_CROPPED_IN)\nprint(\"Test set length: \"+str(len(test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"863425ac13e56ccf1630bca2e99b250d61512d36"},"cell_type":"code","source":"col = ['Image']\ntest_df = pd.DataFrame(test, columns=col)\ntest_df['Id'] = ''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f667d7427013a8b53ddb313b02c4ba26d17446fd"},"cell_type":"code","source":"# X = prepareImages(test_df, test_df.shape[0], TEST_CROPPED)\n# X /= 255","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"40ee34dcab3e10e59bee101856f64756f3d94438"},"cell_type":"markdown","source":"# Test set prediction using generator and flow_from_dataframe <a name=\"flow\"></a>\n____"},{"metadata":{"trusted":true,"_uuid":"3cfbd923f850aadb7f833c0c736fed255bc934b4"},"cell_type":"code","source":"test_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    rescale=1./255,\n    fill_mode='nearest')\n\ntest_generator = test_datagen.flow_from_dataframe(\n    dataframe=test_df, \n    directory=TEST_CROPPED_IN, \n    x_col=\"Image\", \n    y_col=None,\n    class_mode=None,\n    shuffle=False,\n    color_mode= \"rgb\",\n    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), \n    batch_size=1)\n\n#we need to use .reset() here otherwise\n#the other of predictions will be different\n#then the expected\ntest_generator.reset()\npredictions = model.predict_generator(test_generator,verbose = 1,steps=7960)\n\nprint(\"Predictions shape:\")\nprint(np.shape(predictions))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"88d84bade1acbe230a78d6642184ea8c7244d20d"},"cell_type":"markdown","source":"# Test set predictions <a name=\"flow\"></a>\n____"},{"metadata":{"trusted":true,"_uuid":"8447a2d74a3f2aaf0a27a7cb789e05cd14d11199"},"cell_type":"code","source":"# predictions = model.predict(np.array(X), verbose=1)\n# print(np.shape(predictions))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b0dffec7a73ba7f35236207abf179d504a2febfd"},"cell_type":"code","source":"predicted_class_indices=np.argmax(predictions,axis=1)\n\nnp.save(\"predictions.npy\", predictions)\nnp.save(\"predicted_class_indices.npy\", predicted_class_indices)\nnp.save('test_filenames_generator.npy', test_generator.filenames)\nnp.save('test_class_indices.npy', test_generator.class_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4afb5870ef95778722efd231f00673f3c90fd511"},"cell_type":"code","source":"print(labels_list[:7])\nlabels_with_new_whale = np.concatenate((['new_whale'], labels_list), axis=0)    \nprint(labels_with_new_whale[:7])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9feea1e4c22ba5a69fb4b1f3c6658dd4a72f298"},"cell_type":"code","source":"def add_new_whale_to_predictions(preds):\n    sorted_preds = np.sort(preds)\n    avg_of_max_predictions = np.average(sorted_preds[:, -1:])\n    print(\"Average of max probabilities column:\" + str(avg_of_max_predictions))\n    best_threshold = avg_of_max_predictions\n    # print(np.shape(preds))\n    shape_to_add = (np.shape(preds)[0], 1)\n    \n    # Add a column with the best threshold probability to the predictions\n    column_to_add = np.zeros(shape_to_add) + best_threshold\n    predictions_w_new_whale = np.concatenate([column_to_add, preds], axis=1)\n    return predictions_w_new_whale","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2f9bca2b808497aa1c7c0273134e1c3bf3e5ac14"},"cell_type":"code","source":"def create_results_csv(preds, labels_with_new_whale, test_file_names, output_filename):\n    sample_df = pd.read_csv(SAMPLE_SUB)\n    sample_images = list(sample_df.Image)\n    \n    print('Test generator file names:')\n    print(test_file_names[:7])\n    pred_list = [[labels_with_new_whale[i] for i in p.argsort()[-5:][::-1]] for p in preds]\n\n    pred_dic = dict((key, value) for (key, value) in zip(test_file_names, pred_list))\n    pred_list_for_test = [' '.join(pred_dic[i]) for i in sample_images]\n    \n    print('predictions list shape')\n    print(np.shape(pred_list))\n    \n    df = pd.DataFrame({'Image': sample_images, 'Id': pred_list_for_test})\n    df.to_csv(output_filename, header=True, index=False)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true,"_uuid":"ab9c948efa11aaf06dcfd73b88ab426b55d2c0c1"},"cell_type":"code","source":"p = add_new_whale_to_predictions(predictions)\ntest_df = create_results_csv(p, labels_with_new_whale, test_generator.filenames, \"submission.csv\")\nprint(test_df[:10])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}