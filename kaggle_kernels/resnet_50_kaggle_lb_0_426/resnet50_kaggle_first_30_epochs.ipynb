{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HW = 'humpback-whale-identification'\n",
    "TRAIN = '../input/humpback-whale-identification/train/'\n",
    "TEST = '../input/humpback-whale-identification/test/'\n",
    "LABELS = '../input/humpback-whale-identification/train.csv'\n",
    "SAMPLE_SUB = '../input/humpback-whale-identification/sample_submission.csv'\n",
    "BBOX = '../input/metadata/bounding_boxes.csv'\n",
    "\n",
    "whales_bbox = pd.read_csv(BBOX).set_index('Image')\n",
    "\n",
    "train = pd.read_csv(LABELS)\n",
    "print(\"With new_whale:\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "a1dea1195c936c9dd22093483b7a4b32746a978b"
   },
   "outputs": [],
   "source": [
    "MODEL_F = 'Model_ResNet50_30epocs.h5'\n",
    "WEIGHTS_F = 'Weights_ResNet50_30epocs.h5'\n",
    "MODEL = '../input/whales-draft/'+ MODEL_F\n",
    "WEIGHTS = '../input/whales-draft/'+ WEIGHTS_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "d8226025070bee28da643e57f925a6c3c075f63b"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "5c2094ad7d97a11ecd4f7c7dd35cc2cf3fa8ae59"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "from IPython.display import Image\n",
    "# whales_train_modified.describe()\n",
    "\n",
    "#show sample image\n",
    "name = random.choice(train['Image'])\n",
    "print(name)\n",
    "Image(filename=TRAIN+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "b9cd0a1227409ddd9f0154cd51136b84615866d5"
   },
   "outputs": [],
   "source": [
    "train_images = train.set_index('Image')\n",
    "new_whale_train = train_images[train_images.Id == \"new_whale\"]  # only new_whale dataset\n",
    "# whales_train = train_images[~(train_images.Id == \"new_whale\")]  # no new_whale dataset, used for training\n",
    "criteria = train['Id'] != 'new_whale'\n",
    "whales_train = train[criteria]\n",
    "    \n",
    "print(\"Without new_whale:\")\n",
    "whales_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "10d3b64626005f5f0b1714bed949c7178674b6f2"
   },
   "outputs": [],
   "source": [
    "unique_labels = np.unique(whales_train.Id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "fe40c404327ac23b61cf2e1493dd033ece5b7d71"
   },
   "outputs": [],
   "source": [
    "whales_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "9f900184097fc35e7feedde2cc05e5cd00c84d9a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from PIL import Image\n",
    "import gc\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "c60eeebdd134f57556c6e7ef7f7e8151801cae78"
   },
   "outputs": [],
   "source": [
    "def prepareImages(data, m, dataset):\n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((m, 100, 100, 3))\n",
    "    count = 0\n",
    "    \n",
    "    for fig in data['Image']:          \n",
    "        filepath = \"../input/\"+dataset+\"/\"+fig\n",
    "        img = image.load_img(filepath)\n",
    "        img = img.convert(mode=\"RGB\")\n",
    "        \n",
    "        # load bounding box\n",
    "        bbox = whales_bbox.loc[fig]\n",
    "        x0, y0, x1, y1 = bbox['x0'], bbox['y0'], bbox['x1'], bbox['y1']\n",
    "        \n",
    "        # crop according to bounding box\n",
    "        if not (x0 >= x1 or y0 >= y1):\n",
    "            img = img.crop((x0, y0, x1, y1))\n",
    "        #load images into images of size 100x100x3\n",
    "        img = img.resize((100, 100))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        X_train[count] = x\n",
    "        if (count%500 == 0):\n",
    "#             plt.imshow(img)\n",
    "            print(\"Processing image: \", count+1, \", \", fig)\n",
    "            \n",
    "        count += 1\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "8297ce8385ac189ada58f6e59afff905db5997a8"
   },
   "outputs": [],
   "source": [
    "def remove_new_whale():    \n",
    "    labels_dict = dict()\n",
    "    labels_list = []\n",
    "\n",
    "    for i in range(len(unique_labels)):\n",
    "        labels_dict[unique_labels[i]] = i\n",
    "        labels_list.append(unique_labels[i])\n",
    "\n",
    "    print(\"Number of classes: {}\".format(len(unique_labels)))\n",
    "\n",
    "    print(np.shape(labels_list))\n",
    "    labels_list = np.array(labels_list)\n",
    "    return labels_list, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "1aefc26361c9081d77c1bc56b8be852429e8be76"
   },
   "outputs": [],
   "source": [
    "labels_list, labels_dict = remove_new_whale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "2adba4fe7c23e6811da09d977bd055b991099a7c"
   },
   "outputs": [],
   "source": [
    "whales_train.Id = whales_train.Id.apply(lambda x: labels_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "f1e9bb973baf816008dce1381ba518830ffc003c"
   },
   "outputs": [],
   "source": [
    "print(whales_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "97b1b1f7fdc53416b5216ce20c55b0b5d084d202"
   },
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "#     print(integer_encoded)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "#     print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    print(y.shape)\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "1ec77f361f115c9f1e0047000c52d867460167a5"
   },
   "outputs": [],
   "source": [
    "y, label_encoder = prepare_labels(whales_train['Id'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "7043e0c7ebadd67108055625c71147d8a4d04226"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "X = prepareImages(whales_train, whales_train.shape[0], \"humpback-whale-identification/train\")\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "10dbfd1a18557125abc46b6aec885a66a4dcd62e"
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "CLASSES = 5004\n",
    "    \n",
    "# setup model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape = (100, 100, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "predictions = Dense(CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "   \n",
    "# transfer learning\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = True\n",
    "      \n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "f5003f0bdffcd3c8c0a95d02917cc2ee42ade4f5"
   },
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# # returns a compiled model\n",
    "# # identical to the previous cell\n",
    "# model = load_model(MODEL)\n",
    "# print(\"Loaded model architecture from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "6164ebdca0950095114b245ca9e834c43d2947af"
   },
   "outputs": [],
   "source": [
    "print(\"Train set shape: \"+ str(np.shape(X)))\n",
    "print(np.shape(whales_train['Id']))\n",
    "history = model.fit(X, y, epochs=30, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "1ad42778204ccee6119faa6eaebd69edc66cfc6a"
   },
   "outputs": [],
   "source": [
    "model.save(MODEL_F)\n",
    "print(\"Saved model architecture to disk\")\n",
    "model.save_weights(WEIGHTS_F)\n",
    "print(\"Saved model weights to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "c4a1a6be045ecb003b33b899ed11ebedbde4befd"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "a828703f48eb3defa1ed5d5b7ec058b5c2e3f1ac"
   },
   "outputs": [],
   "source": [
    "# model.load_weights(WEIGHTS)\n",
    "# print(\"Loaded model weifhts from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "4803d5306931ad157b9fb9bf3923166d8fd68a0c"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "2642d18e30e2731f7d4750ba6fd01ec11188dd92"
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "848dd2761765e9512ff700372e34b39c469ede1e"
   },
   "outputs": [],
   "source": [
    "test = os.listdir(TEST)\n",
    "print(\"Test set length: \"+str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "863425ac13e56ccf1630bca2e99b250d61512d36"
   },
   "outputs": [],
   "source": [
    "col = ['Image']\n",
    "test_df = pd.DataFrame(test, columns=col)\n",
    "test_df['Id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "f667d7427013a8b53ddb313b02c4ba26d17446fd"
   },
   "outputs": [],
   "source": [
    "X = prepareImages(test_df, test_df.shape[0], \"humpback-whale-identification/test\")\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "8447a2d74a3f2aaf0a27a7cb789e05cd14d11199"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(np.array(X), verbose=1)\n",
    "print(np.shape(predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "trusted": true,
    "_uuid": "b0dffec7a73ba7f35236207abf179d504a2febfd"
   },
   "source": [
    "np.save(\"test_files.npy\", test)\nnp.save(\"one_hot_predss.npy\", predictions)\nnp.save(\"one_hot_encoder.npy\", label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "4afb5870ef95778722efd231f00673f3c90fd511"
   },
   "outputs": [],
   "source": [
    "print(labels_list[:7])\n",
    "labels_with_new_whale = ['new_whale']\n",
    "                         \n",
    "for s in labels_list:\n",
    "    labels_with_new_whale.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "c9feea1e4c22ba5a69fb4b1f3c6658dd4a72f298"
   },
   "outputs": [],
   "source": [
    "def add_new_whale_to_predictions(preds):\n",
    "    sorted_preds = np.sort(preds)\n",
    "    avg_of_max_predictions = np.average(sorted_preds[:, -1:])\n",
    "    print(\"Average of max probabilities column:\" + str(avg_of_max_predictions))\n",
    "    best_threshold = avg_of_max_predictions\n",
    "    # print(np.shape(preds))\n",
    "    shape_to_add = (np.shape(preds)[0], 1)\n",
    "    \n",
    "    # Add a column with the best threshold probability to the predictions\n",
    "    column_to_add = np.zeros(shape_to_add) + best_threshold\n",
    "    predictions_w_new_whale = np.concatenate([column_to_add, preds], axis=1)\n",
    "    return predictions_w_new_whale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "2f9bca2b808497aa1c7c0273134e1c3bf3e5ac14"
   },
   "outputs": [],
   "source": [
    "def create_results_csv(preds, labels_with_new_whale, test_file_names, output_filename):\n",
    "    sample_df = pd.read_csv(SAMPLE_SUB)\n",
    "    sample_images = list(sample_df.Image)\n",
    "\n",
    "    print(test_file_names[:7])\n",
    "    pred_list = [[labels_with_new_whale[i] for i in p.argsort()[-5:][::-1]] for p in preds]\n",
    "\n",
    "    pred_dic = dict((key, value) for (key, value) in zip(test_file_names, pred_list))\n",
    "    pred_list_for_test = [' '.join(pred_dic[id]) for id in sample_images]\n",
    "\n",
    "    print(np.shape(pred_list))\n",
    "    print(np.shape(test_file_names))\n",
    "    df = pd.DataFrame({'Image': sample_images, 'Id': pred_list_for_test})\n",
    "    df.to_csv(output_filename, header=True, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "trusted": true,
    "_uuid": "ab9c948efa11aaf06dcfd73b88ab426b55d2c0c1"
   },
   "outputs": [],
   "source": [
    "p = add_new_whale_to_predictions(predictions)\n",
    "test_df = create_results_csv(p, labels_with_new_whale, test, \"submission.csv\")\n",
    "print(test_df[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
