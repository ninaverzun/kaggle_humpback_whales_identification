{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "HW = 'humpback-whale-identification'\n",
    "# TRAIN = '../input/humpback-whale-identification/train/'\n",
    "TRAIN_CROPPED = \"whales-cropped/cropped_train/cropped_train/\"\n",
    "TRAIN_CROPPED_IN = '../input/' + TRAIN_CROPPED\n",
    "\n",
    "# TEST = '../input/humpback-whale-identification/test/'\n",
    "TEST_CROPPED = \"whales-cropped/cropped_test/cropped_test/\"\n",
    "TEST_CROPPED_IN = '../input/' + TEST_CROPPED\n",
    "\n",
    "LABELS = '../input/humpback-whale-identification/train.csv'\n",
    "SAMPLE_SUB = '../input/humpback-whale-identification/sample_submission.csv'\n",
    "\n",
    "train = pd.read_csv(LABELS)\n",
    "print(\"With new_whale:\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "a1dea1195c936c9dd22093483b7a4b32746a978b"
   },
   "outputs": [],
   "source": [
    "MODEL_F = 'Model_Xception_flow.h5'\n",
    "WEIGHTS_F = 'Weights_Xception_flow.h5'\n",
    "MODEL = '../input/Xception-pretrained/'+ MODEL_F\n",
    "WEIGHTS = '../input/Xception-pretrained/'+ WEIGHTS_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "d8226025070bee28da643e57f925a6c3c075f63b"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "5c2094ad7d97a11ecd4f7c7dd35cc2cf3fa8ae59"
   },
   "outputs": [],
   "source": [
    "import random \n",
    "from IPython.display import Image\n",
    "print(\"Example whale image\")\n",
    "\n",
    "#show sample image\n",
    "name = random.choice(train['Image'])\n",
    "print(name)\n",
    "Image(filename = TRAIN_CROPPED_IN + name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "b9cd0a1227409ddd9f0154cd51136b84615866d5"
   },
   "outputs": [],
   "source": [
    "train_images = train.set_index('Image')\n",
    "new_whale_train = train_images[train_images.Id == \"new_whale\"]  # only new_whale dataset\n",
    "# whales_train = train_images[~(train_images.Id == \"new_whale\")]  # no new_whale dataset, used for training\n",
    "criteria = train['Id'] != 'new_whale'\n",
    "whales_train = train[criteria]\n",
    "    \n",
    "print(\"Without new_whale:\")\n",
    "whales_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "10d3b64626005f5f0b1714bed949c7178674b6f2"
   },
   "outputs": [],
   "source": [
    "unique_labels = np.unique(whales_train.Id.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "fe40c404327ac23b61cf2e1493dd033ece5b7d71"
   },
   "outputs": [],
   "source": [
    "whales_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "9f900184097fc35e7feedde2cc05e5cd00c84d9a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras import layers\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "\n",
    "from keras.losses import binary_crossentropy\n",
    "\n",
    "from keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D, GlobalAveragePooling2D\n",
    "from keras.layers import AveragePooling2D, MaxPooling2D, Dropout\n",
    "from keras.models import Model\n",
    "\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from PIL import Image\n",
    "import gc\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "c60eeebdd134f57556c6e7ef7f7e8151801cae78"
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "IMAGE_SHAPE = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n",
    "\n",
    "def prepareImages(data, m, dataset):\n",
    "    print(\"Preparing images\")\n",
    "    X_train = np.zeros((m, IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "    count = 0\n",
    "    \n",
    "    for fig in data['Image']:          \n",
    "        filepath = \"../input/\"+dataset+\"/\"+fig\n",
    "        img = image.load_img(filepath)\n",
    "        img = img.convert(mode=\"RGB\")\n",
    "        \n",
    "        #load images into images of required size\n",
    "        img = img.resize((IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "        x = image.img_to_array(img)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        X_train[count] = x\n",
    "        if (count%500 == 0):\n",
    "            print(\"Processing image: \", count+1, \", \", fig)\n",
    "            \n",
    "        count += 1\n",
    "    \n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "8297ce8385ac189ada58f6e59afff905db5997a8"
   },
   "outputs": [],
   "source": [
    "def remove_new_whale():    \n",
    "    labels_dict = dict()\n",
    "    labels_list = []\n",
    "\n",
    "    for i in range(len(unique_labels)):\n",
    "        labels_dict[unique_labels[i]] = i\n",
    "        labels_list.append(unique_labels[i])\n",
    "\n",
    "    print(\"Number of classes: {}\".format(len(unique_labels)))\n",
    "\n",
    "    print(np.shape(labels_list))\n",
    "    labels_list = np.array(labels_list)\n",
    "    return labels_list, labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "1aefc26361c9081d77c1bc56b8be852429e8be76"
   },
   "outputs": [],
   "source": [
    "labels_list, labels_dict = remove_new_whale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "2adba4fe7c23e6811da09d977bd055b991099a7c"
   },
   "outputs": [],
   "source": [
    "whales_train.Id = whales_train.Id.apply(lambda x: labels_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "f1e9bb973baf816008dce1381ba518830ffc003c"
   },
   "outputs": [],
   "source": [
    "print(whales_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "97b1b1f7fdc53416b5216ce20c55b0b5d084d202"
   },
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "    # print(integer_encoded)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "#     print(integer_encoded)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "#     print(onehot_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    print(y.shape)\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "1ec77f361f115c9f1e0047000c52d867460167a5"
   },
   "outputs": [],
   "source": [
    "y, label_encoder = prepare_labels(whales_train['Id'])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "7043e0c7ebadd67108055625c71147d8a4d04226"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "X = prepareImages(whales_train, whales_train.shape[0], TRAIN_CROPPED)\n",
    "X /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "10dbfd1a18557125abc46b6aec885a66a4dcd62e"
   },
   "outputs": [],
   "source": [
    "CLASSES = 5004\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# setup model\n",
    "base_model = Xception(weights='imagenet', include_top=False, input_shape = IMAGE_SHAPE)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = Dropout(0.4)(x)\n",
    "predictions = Dense(CLASSES, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "   \n",
    "# transfer learning\n",
    "for layer in base_model.layers:\n",
    "  layer.trainable = True\n",
    "      \n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "6164ebdca0950095114b245ca9e834c43d2947af"
   },
   "outputs": [],
   "source": [
    "print(\"Train set shape: \"+ str(np.shape(X)))\n",
    "print(np.shape(whales_train['Id']))\n",
    "history = model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "22122a13725cba722699bf12e48c46d7d55c14f9"
   },
   "outputs": [],
   "source": [
    "# validate\n",
    "val_set_x = X[1000:6000]\n",
    "val_set_y = y[1000:6000]\n",
    "scores = model.evaluate(val_set_x, val_set_y, verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "1ad42778204ccee6119faa6eaebd69edc66cfc6a"
   },
   "outputs": [],
   "source": [
    "model.save(MODEL_F)\n",
    "print(\"Saved model architecture to disk\")\n",
    "model.save_weights(WEIGHTS_F)\n",
    "print(\"Saved model weights to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "c4a1a6be045ecb003b33b899ed11ebedbde4befd"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "a828703f48eb3defa1ed5d5b7ec058b5c2e3f1ac"
   },
   "outputs": [],
   "source": [
    "# from keras.models import load_model\n",
    "\n",
    "# # returns a compiled model\n",
    "# # identical to the previous cell\n",
    "# model = load_model(MODEL)\n",
    "# print(\"Loaded model architecture from disk\")\n",
    "\n",
    "# model.load_weights(WEIGHTS)\n",
    "# print(\"Loaded model weights from disk\")\n",
    "# model.summary()\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "adbc27074f20f494670395569611c751963d2140"
   },
   "source": [
    "# Plot train results <a name=\"flow\"></a>\n____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "4803d5306931ad157b9fb9bf3923166d8fd68a0c"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "    \n",
    "l1 = plt.plot(acc, label='acc')\n",
    "# l2 = plt.plot(val_acc, label='val_acc')\n",
    "plt.legend(loc=2, fontsize=\"small\")\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "2642d18e30e2731f7d4750ba6fd01ec11188dd92"
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "l1 = plt.plot(loss, label='loss')\n",
    "# plt.plot(val_loss, label='val_loss')\n",
    "plt.legend(loc=2, fontsize=\"small\")\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "848dd2761765e9512ff700372e34b39c469ede1e"
   },
   "outputs": [],
   "source": [
    "test = os.listdir(TEST_CROPPED_IN)\n",
    "print(\"Test set length: \"+str(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "863425ac13e56ccf1630bca2e99b250d61512d36"
   },
   "outputs": [],
   "source": [
    "col = ['Image']\n",
    "test_df = pd.DataFrame(test, columns=col)\n",
    "test_df['Id'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "f667d7427013a8b53ddb313b02c4ba26d17446fd"
   },
   "outputs": [],
   "source": [
    "X = prepareImages(test_df, test_df.shape[0], TEST_CROPPED)\n",
    "# X /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "40ee34dcab3e10e59bee101856f64756f3d94438"
   },
   "source": [
    "# Test set prediction using generator and flow_from_dataframe <a name=\"flow\"></a>\n____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "3cfbd923f850aadb7f833c0c736fed255bc934b4"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rescale=1./255,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df, \n",
    "    directory=TEST_CROPPED_IN, \n",
    "    x_col=\"Image\", \n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    color_mode= \"rgb\",\n",
    "    target_size=(IMAGE_HEIGHT, IMAGE_WIDTH), \n",
    "    batch_size=1)\n",
    "\n",
    "#we need to use .reset() here otherwise\n",
    "#the other of predictions will be different\n",
    "#then the expected\n",
    "test_generator.reset()\n",
    "predictions = model.predict_generator(test_generator,verbose = 1,steps=7960)\n",
    "\n",
    "print(\"Predictions shape:\")\n",
    "print(np.shape(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "88d84bade1acbe230a78d6642184ea8c7244d20d"
   },
   "source": [
    "# Test set predictions <a name=\"flow\"></a>\n____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "8447a2d74a3f2aaf0a27a7cb789e05cd14d11199"
   },
   "outputs": [],
   "source": [
    "# predictions = model.predict(np.array(X), verbose=1)\n",
    "# print(np.shape(predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "b0dffec7a73ba7f35236207abf179d504a2febfd"
   },
   "outputs": [],
   "source": [
    "predicted_class_indices=np.argmax(predictions,axis=1)\n",
    "\n",
    "np.save(\"predictions.npy\", predictions)\n",
    "np.save(\"predicted_class_indices.npy\", predicted_class_indices)\n",
    "np.save('test_filenames_generator.npy', test_generator.filenames)\n",
    "np.save('test_class_indices.npy', test_generator.class_indices)\n",
    "\n",
    "print('predicted class indices:')\n",
    "print(predicted_class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "4afb5870ef95778722efd231f00673f3c90fd511"
   },
   "outputs": [],
   "source": [
    "print(labels_list[:7])\n",
    "labels_with_new_whale = np.concatenate((['new_whale'], labels_list), axis=0)    \n",
    "print(labels_with_new_whale[:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "c9feea1e4c22ba5a69fb4b1f3c6658dd4a72f298"
   },
   "outputs": [],
   "source": [
    "def add_new_whale_to_predictions(preds):\n",
    "    sorted_preds = np.sort(preds)\n",
    "    avg_of_max_predictions = np.average(sorted_preds[:, -1:])\n",
    "    print(\"Average of max probabilities column:\" + str(avg_of_max_predictions))\n",
    "    best_threshold = avg_of_max_predictions\n",
    "    # print(np.shape(preds))\n",
    "    shape_to_add = (np.shape(preds)[0], 1)\n",
    "    \n",
    "    # Add a column with the best threshold probability to the predictions\n",
    "    column_to_add = np.zeros(shape_to_add) + best_threshold\n",
    "    predictions_w_new_whale = np.concatenate([column_to_add, preds], axis=1)\n",
    "    return predictions_w_new_whale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true,
    "_uuid": "2f9bca2b808497aa1c7c0273134e1c3bf3e5ac14"
   },
   "outputs": [],
   "source": [
    "def create_results_csv(preds, labels_with_new_whale, test_file_names, output_filename):\n",
    "    sample_df = pd.read_csv(SAMPLE_SUB)\n",
    "    sample_images = list(sample_df.Image)\n",
    "    \n",
    "    print('Test generator file names:')\n",
    "    print(test_file_names[:7])\n",
    "    pred_list = [[labels_with_new_whale[i] for i in p.argsort()[-5:][::-1]] for p in preds]\n",
    "\n",
    "    pred_dic = dict((key, value) for (key, value) in zip(test_file_names, pred_list))\n",
    "    pred_list_for_test = [' '.join(pred_dic[i]) for i in sample_images]\n",
    "    \n",
    "    print('predictions list shape')\n",
    "    print(np.shape(pred_list))\n",
    "    \n",
    "    df = pd.DataFrame({'Image': sample_images, 'Id': pred_list_for_test})\n",
    "    df.to_csv(output_filename, header=True, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": false,
    "trusted": true,
    "_uuid": "ab9c948efa11aaf06dcfd73b88ab426b55d2c0c1"
   },
   "outputs": [],
   "source": [
    "p = add_new_whale_to_predictions(predictions)\n",
    "test_df = create_results_csv(p, labels_with_new_whale, test_generator.filenames, \"submission.csv\")\n",
    "print(test_df[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
